{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhYzCIUR3_c-"
   },
   "source": [
    "# colab용 자동화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29119,
     "status": "ok",
     "timestamp": 1599453840285,
     "user": {
      "displayName": "이경찬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj56GLoLaRW56a8OPmpFhv1BaU-InaJEauJiWWicQ=s64",
      "userId": "06819814280514699015"
     },
     "user_tz": -540
    },
    "id": "Qfydwsng3_c_",
    "outputId": "dbdf3f0a-32b4-4097-e210-f78102447494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14007354,
     "status": "ok",
     "timestamp": 1599467897563,
     "user": {
      "displayName": "이경찬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj56GLoLaRW56a8OPmpFhv1BaU-InaJEauJiWWicQ=s64",
      "userId": "06819814280514699015"
     },
     "user_tz": -540
    },
    "id": "vvE_V3Gy3_dD",
    "outputId": "49b5d27b-6c6e-4e31-b775-3aef8edd319f"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/Shared drives/BigData/team__KU/data/result.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-00a0644a38d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# 불러올때\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/Shared drives/BigData/team__KU/data/result.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/Shared drives/BigData/team__KU/data/result.txt'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# from soynlp.hangle import levenshtein\n",
    "# # from PreProcessing.find_common_part\n",
    "# from konlpy.tag import *\n",
    "# from PreProcessing import find_common_part\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 불러올때    \n",
    "with open('/content/drive/Shared drives/BigData/team__KU/data/result.txt', 'rb') as f:\n",
    "    result = pickle.load(f)\n",
    "\n",
    "result_gensim_input = [_.split() for _ in result if _ != '']\n",
    "result_tokenizer_input = [v for i, v in enumerate(result) if i%2 == 0 and v != '']\n",
    "ebs_in_result_for_getting_max_len = [v for i, v in enumerate(result_gensim_input) if i%2 == 0 and v != []]\n",
    "ebs_in_result_gensim_input = [v for i, v in enumerate(result_gensim_input) if i%2 == 0 and v != [] ]\n",
    "google_in_result_gensim_input = [v for i, v in enumerate(result_gensim_input) if i%2 == 1 and v != []]\n",
    "    \n",
    "# Generate EBS string vectors matrix\n",
    "ws = 1\n",
    "es = 30\n",
    "\n",
    "model_cbow = Word2Vec(\n",
    "                ebs_in_result_gensim_input, \n",
    "                window = ws,\n",
    "                size =es,\n",
    "                min_count=1,\n",
    "                workers = 10\n",
    "                )\n",
    "vocabs = list(model_cbow.wv.index2word)\n",
    "embedding_matrix = np.zeros((len(vocabs), es))\n",
    "for i, w in enumerate(vocabs):\n",
    "    embedding_matrix[i] = model_cbow[w]\n",
    "\n",
    "#embedding_matrix 맨 위에 0벡터 추가\n",
    "stacked_zero = np.zeros((1, es))\n",
    "embedding_matrix = np.vstack((stacked_zero, embedding_matrix))\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(result_tokenizer_input)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "#시퀀스 만들기\n",
    "sequences = list()\n",
    "\n",
    "for line in result_tokenizer_input: # 1,214 개의 샘플에 대해서 샘플을 1개씩 가져온다.\n",
    "    encoded = t.texts_to_sequences([line])[0] # 각 샘플에 대한 정수 인코딩\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[i-9 if i > 9 else 0:i+1]\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "max_len=max(len(l) for l in sequences)\n",
    "print('max length : {}'.format(max_len))\n",
    "\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]\n",
    "\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "embedding_layer = Embedding(vocab_size,\n",
    "                            es,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_len,\n",
    "                            trainable=False)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "# y데이터를 분리하였으므로 이제 X데이터의 길이는 기존 데이터의 길이 - 1\n",
    "model.add(LSTM(128, activation = 'relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, batch_size = 40, epochs=400, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ar7q9PL04V-F"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ebs_in_result_gensim_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7ec8d056d40d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mebs_in_result_gensim_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ebs_in_result_gensim_input' is not defined"
     ]
    }
   ],
   "source": [
    "ebs_in_result_gensim_input"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "colab learning - pre400.ipynb의 사본",
   "provenance": [
    {
     "file_id": "1R35jFTsEgZ41ILmR2I6xfuKwmTEeVgi1",
     "timestamp": 1599473427628
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
