{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"colab learning_index_rev-30.ipynb의 사본","provenance":[{"file_id":"1F6I5rm9iyydu31s9j86fe5tpEg2gs14v","timestamp":1599312572960}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"GKPhP5vhX6qv","colab_type":"text"},"source":["# colab용 자동화"]},{"cell_type":"code","metadata":{"id":"qjk1ffPeX6qy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1599311226101,"user_tz":-540,"elapsed":25404,"user":{"displayName":"이경찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj56GLoLaRW56a8OPmpFhv1BaU-InaJEauJiWWicQ=s64","userId":"06819814280514699015"}},"outputId":"4c5a8193-bfab-43de-d02c-d5aef2db10e8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wS3-5G_MX6q5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599312553292,"user_tz":-540,"elapsed":1249702,"user":{"displayName":"이경찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj56GLoLaRW56a8OPmpFhv1BaU-InaJEauJiWWicQ=s64","userId":"06819814280514699015"}},"outputId":"7bc82429-9b96-480f-c2ba-bac13dfa2fb7"},"source":["import pickle\n","# from soynlp.hangle import levenshtein\n","# # from PreProcessing.find_common_part\n","# from konlpy.tag import *\n","# from PreProcessing import find_common_part\n","import numpy as np\n","from gensim.models import Word2Vec\n","from keras.layers import Embedding\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dense, LSTM\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","\n","# 불러올때    \n","with open('/content/drive/Shared drives/BigData/team__KU/data/result.txt', 'rb') as f:\n","    result = pickle.load(f)\n","\n","result_gensim_input = [_.split() for _ in result if _ != '']\n","result_tokenizer_input = [v for i, v in enumerate(result) if i%2 == 0 and v != '']\n","ebs_in_result_for_getting_max_len = [v for i, v in enumerate(result_gensim_input) if i%2 == 0 and v != []]\n","ebs_in_result_gensim_input = [v for i, v in enumerate(result_gensim_input) if i%2 == 0 and v != [] ]\n","google_in_result_gensim_input = [v for i, v in enumerate(result_gensim_input) if i%2 == 1 and v != []]\n","    \n","# Generate EBS string vectors matrix\n","ws = 1\n","es = 30\n","\n","model_cbow = Word2Vec(\n","                ebs_in_result_gensim_input, \n","                window = ws,\n","                size =es,\n","                min_count=1,\n","                workers = 10\n","                )\n","vocabs = list(model_cbow.wv.index2word)\n","embedding_matrix = np.zeros((len(vocabs), es))\n","for i, w in enumerate(vocabs):\n","    embedding_matrix[i] = model_cbow[w]\n","\n","#embedding_matrix 맨 위에 0벡터 추가\n","stacked_zero = np.zeros((1, es))\n","embedding_matrix = np.vstack((stacked_zero, embedding_matrix))\n","\n","t = Tokenizer()\n","t.fit_on_texts(result_tokenizer_input)\n","vocab_size = len(t.word_index) + 1\n","\n","#시퀀스 만들기\n","sequences = list()\n","\n","for line in result_tokenizer_input: # 1,214 개의 샘플에 대해서 샘플을 1개씩 가져온다.\n","    encoded = t.texts_to_sequences([line])[0] # 각 샘플에 대한 정수 인코딩\n","    for i in range(1, len(encoded)):\n","        sequence = encoded[i-9 if i > 9 else 0:i+1]\n","        sequences.append(sequence)\n","        \n","max_len=max(len(l) for l in sequences)\n","print('max length : {}'.format(max_len))\n","\n","sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n","\n","sequences = np.array(sequences)\n","X = sequences[:,:-1]\n","y = sequences[:,-1]\n","\n","y = to_categorical(y, num_classes=vocab_size)\n","\n","embedding_layer = Embedding(vocab_size,\n","                            es,\n","                            weights=[embedding_matrix],\n","                            input_length=max_len,\n","                            trainable=False)\n","\n","model = Sequential()\n","model.add(embedding_layer)\n","# y데이터를 분리하였으므로 이제 X데이터의 길이는 기존 데이터의 길이 - 1\n","model.add(LSTM(128, activation = 'relu'))\n","model.add(Dense(vocab_size, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(X, y, epochs=30, verbose=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"],"name":"stderr"},{"output_type":"stream","text":["max length : 10\n","Epoch 1/30\n","WARNING:tensorflow:Model was constructed with shape (None, 10) for input Tensor(\"embedding_input:0\", shape=(None, 10), dtype=float32), but it was called on an input with incompatible shape (None, 9).\n","WARNING:tensorflow:Model was constructed with shape (None, 10) for input Tensor(\"embedding_input:0\", shape=(None, 10), dtype=float32), but it was called on an input with incompatible shape (None, 9).\n","1558/1558 - 41s - loss: 7.7723 - accuracy: 0.0169\n","Epoch 2/30\n","1558/1558 - 41s - loss: 7.4155 - accuracy: 0.0201\n","Epoch 3/30\n","1558/1558 - 42s - loss: 7.2729 - accuracy: 0.0231\n","Epoch 4/30\n","1558/1558 - 41s - loss: 7.1356 - accuracy: 0.0256\n","Epoch 5/30\n","1558/1558 - 41s - loss: 7.0230 - accuracy: 0.0283\n","Epoch 6/30\n","1558/1558 - 41s - loss: 6.9051 - accuracy: 0.0311\n","Epoch 7/30\n","1558/1558 - 41s - loss: 6.7655 - accuracy: 0.0347\n","Epoch 8/30\n","1558/1558 - 41s - loss: 6.5992 - accuracy: 0.0377\n","Epoch 9/30\n","1558/1558 - 42s - loss: 6.4262 - accuracy: 0.0403\n","Epoch 10/30\n","1558/1558 - 41s - loss: 6.2443 - accuracy: 0.0431\n","Epoch 11/30\n","1558/1558 - 42s - loss: 6.0541 - accuracy: 0.0453\n","Epoch 12/30\n","1558/1558 - 41s - loss: 5.8451 - accuracy: 0.0469\n","Epoch 13/30\n","1558/1558 - 41s - loss: 5.6118 - accuracy: 0.0497\n","Epoch 14/30\n","1558/1558 - 41s - loss: 5.3598 - accuracy: 0.0624\n","Epoch 15/30\n","1558/1558 - 41s - loss: 5.1094 - accuracy: 0.1010\n","Epoch 16/30\n","1558/1558 - 42s - loss: 4.8899 - accuracy: 0.1457\n","Epoch 17/30\n","1558/1558 - 41s - loss: 4.7106 - accuracy: 0.1774\n","Epoch 18/30\n","1558/1558 - 42s - loss: 4.5581 - accuracy: 0.2015\n","Epoch 19/30\n","1558/1558 - 42s - loss: 4.4324 - accuracy: 0.2162\n","Epoch 20/30\n","1558/1558 - 42s - loss: 4.3196 - accuracy: 0.2300\n","Epoch 21/30\n","1558/1558 - 41s - loss: 4.2179 - accuracy: 0.2419\n","Epoch 22/30\n","1558/1558 - 41s - loss: 4.1263 - accuracy: 0.2527\n","Epoch 23/30\n","1558/1558 - 41s - loss: 4.0444 - accuracy: 0.2602\n","Epoch 24/30\n","1558/1558 - 41s - loss: 3.9694 - accuracy: 0.2707\n","Epoch 25/30\n","1558/1558 - 41s - loss: 3.8980 - accuracy: 0.2783\n","Epoch 26/30\n","1558/1558 - 41s - loss: 3.8322 - accuracy: 0.2859\n","Epoch 27/30\n","1558/1558 - 40s - loss: 3.7716 - accuracy: 0.2942\n","Epoch 28/30\n","1558/1558 - 41s - loss: 3.7140 - accuracy: 0.3007\n","Epoch 29/30\n","1558/1558 - 41s - loss: 3.6601 - accuracy: 0.3061\n","Epoch 30/30\n","1558/1558 - 41s - loss: 3.6096 - accuracy: 0.3137\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f75f04ea208>"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"64MTVM3EX6rA","colab_type":"text"},"source":["# --------------------------------------------------------------------"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"QXW0zf2nX6rB","colab_type":"code","colab":{}},"source":["# for _ in list(range(10,160,10)):\n","model_skip = Word2Vec(\n","result_gensim_input, \n","window = 2,\n","size =100,\n","min_count=1,\n","workers = 10\n",")\n","print(_)\n","print('집값삼각형 : ', model_skip.most_similar('집값삼각형',topn=5))\n","print()\n","print('도영 : ', model_skip.most_similar('도영',topn=5))\n","print()\n","print('싸인 : ', model_skip.most_similar('싸인',topn=5))\n","print()\n","print('수박 : ',model_skip.most_similar('수박',topn=5)) \n","print()\n","print('가게대변인 : ',model_skip.most_similar('가게대변인',topn=5))\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iU6JffQLX6rI","colab_type":"code","colab":{}},"source":["# model_skip = Word2Vec(\n","#     result_gensim_input, \n","#     window = 2,\n","#     size =40,\n","#     min_count=1,\n","#     sg = 1,\n","#     workers = 10\n","# )\n","# print(model_skip)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x_LYg3n3X6rN","colab_type":"code","colab":{}},"source":["model_skip.most_similar('집값삼각형',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cvVtE2cUX6rT","colab_type":"code","colab":{}},"source":["model_skip.most_similar('도영',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ywU9CBpX6rY","colab_type":"code","colab":{}},"source":["model_skip.most_similar('싸인',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9bfk-rI_X6rh","colab_type":"code","colab":{}},"source":["model_skip.most_similar('수박',topn=10) #특수각"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LbzlgeglX6rk","colab_type":"code","colab":{}},"source":["model_skip.most_similar('가게대변인',topn=10) #각의대변"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4rJh7V0dX6rn","colab_type":"code","colab":{}},"source":["model_skip.most_similar('추위',topn=10) #최애"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x1jpoDt9X6rp","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2lI8bIykX6rt","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PN7yhaK0X6rv","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f5qTn9NcX6ry","colab_type":"code","colab":{}},"source":["model_skip.most_similar('',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K76ZD51YX6r1","colab_type":"code","colab":{}},"source":["model_skip.most_similar('',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ifgwJwmFX6r4","colab_type":"code","colab":{}},"source":["model_skip.most_similar('',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VDAOXitnX6r7","colab_type":"code","colab":{}},"source":["model_skip.most_similar('',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R7DBXkt5X6r-","colab_type":"code","colab":{}},"source":["model_skip.most_similar('',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0vU28nIFX6sA","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DqHwUFAhX6sD","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lF7saasZX6sG","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NH28m0LMX6sI","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSBA4FQGX6sK","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}