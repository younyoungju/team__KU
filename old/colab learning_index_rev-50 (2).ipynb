{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"colab learning_index_rev-50.ipynb의 사본","provenance":[{"file_id":"1Q9dv01ywHU0OiEg4xy6UtbuyBSPe0Upq","timestamp":1599315554916}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"qfhFkZTfX7qJ","colab_type":"text"},"source":["# colab용 자동화"]},{"cell_type":"code","metadata":{"id":"TU9Wu5JUX7qK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1599311212919,"user_tz":-540,"elapsed":36640,"user":{"displayName":"이경찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj56GLoLaRW56a8OPmpFhv1BaU-InaJEauJiWWicQ=s64","userId":"06819814280514699015"}},"outputId":"9cf9e5b3-4f21-41a1-d610-db67d781dc15"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mhhIP-zPX7qN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599313315306,"user_tz":-540,"elapsed":2004987,"user":{"displayName":"이경찬","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj56GLoLaRW56a8OPmpFhv1BaU-InaJEauJiWWicQ=s64","userId":"06819814280514699015"}},"outputId":"fc9d1d63-b1df-4789-dd88-c922ec4ddc4a"},"source":["import pickle\n","# from soynlp.hangle import levenshtein\n","# # from PreProcessing.find_common_part\n","# from konlpy.tag import *\n","# from PreProcessing import find_common_part\n","import numpy as np\n","from gensim.models import Word2Vec\n","from keras.layers import Embedding\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dense, LSTM\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","\n","# 불러올때    \n","with open('/content/drive/Shared drives/BigData/team__KU/data/result.txt', 'rb') as f:\n","    result = pickle.load(f)\n","\n","result_gensim_input = [_.split() for _ in result if _ != '']\n","result_tokenizer_input = [v for i, v in enumerate(result) if i%2 == 0 and v != '']\n","ebs_in_result_for_getting_max_len = [v for i, v in enumerate(result_gensim_input) if i%2 == 0 and v != []]\n","ebs_in_result_gensim_input = [v for i, v in enumerate(result_gensim_input) if i%2 == 0 and v != [] ]\n","google_in_result_gensim_input = [v for i, v in enumerate(result_gensim_input) if i%2 == 1 and v != []]\n","    \n","# Generate EBS string vectors matrix\n","ws = 1\n","es = 30\n","\n","model_cbow = Word2Vec(\n","                ebs_in_result_gensim_input, \n","                window = ws,\n","                size =es,\n","                min_count=1,\n","                workers = 10\n","                )\n","vocabs = list(model_cbow.wv.index2word)\n","embedding_matrix = np.zeros((len(vocabs), es))\n","for i, w in enumerate(vocabs):\n","    embedding_matrix[i] = model_cbow[w]\n","\n","#embedding_matrix 맨 위에 0벡터 추가\n","stacked_zero = np.zeros((1, es))\n","embedding_matrix = np.vstack((stacked_zero, embedding_matrix))\n","\n","t = Tokenizer()\n","t.fit_on_texts(result_tokenizer_input)\n","vocab_size = len(t.word_index) + 1\n","\n","#시퀀스 만들기\n","sequences = list()\n","\n","for line in result_tokenizer_input: # 1,214 개의 샘플에 대해서 샘플을 1개씩 가져온다.\n","    encoded = t.texts_to_sequences([line])[0] # 각 샘플에 대한 정수 인코딩\n","    for i in range(1, len(encoded)):\n","        sequence = encoded[i-9 if i > 9 else 0:i+1]\n","        sequences.append(sequence)\n","        \n","max_len=max(len(l) for l in sequences)\n","print('max length : {}'.format(max_len))\n","\n","sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n","\n","sequences = np.array(sequences)\n","X = sequences[:,:-1]\n","y = sequences[:,-1]\n","\n","y = to_categorical(y, num_classes=vocab_size)\n","\n","embedding_layer = Embedding(vocab_size,\n","                            es,\n","                            weights=[embedding_matrix],\n","                            input_length=max_len,\n","                            trainable=False)\n","\n","model = Sequential()\n","model.add(embedding_layer)\n","# y데이터를 분리하였으므로 이제 X데이터의 길이는 기존 데이터의 길이 - 1\n","model.add(LSTM(128, activation = 'relu'))\n","model.add(Dense(vocab_size, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(X, y, epochs=50, verbose=2)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"],"name":"stderr"},{"output_type":"stream","text":["max length : 10\n","Epoch 1/50\n","WARNING:tensorflow:Model was constructed with shape (None, 10) for input Tensor(\"embedding_input:0\", shape=(None, 10), dtype=float32), but it was called on an input with incompatible shape (None, 9).\n","WARNING:tensorflow:Model was constructed with shape (None, 10) for input Tensor(\"embedding_input:0\", shape=(None, 10), dtype=float32), but it was called on an input with incompatible shape (None, 9).\n","1558/1558 - 40s - loss: 7.7710 - accuracy: 0.0160\n","Epoch 2/50\n","1558/1558 - 40s - loss: 7.4106 - accuracy: 0.0204\n","Epoch 3/50\n","1558/1558 - 40s - loss: 7.2496 - accuracy: 0.0242\n","Epoch 4/50\n","1558/1558 - 40s - loss: 7.1129 - accuracy: 0.0248\n","Epoch 5/50\n","1558/1558 - 40s - loss: 6.9853 - accuracy: 0.0260\n","Epoch 6/50\n","1558/1558 - 40s - loss: 6.8546 - accuracy: 0.0283\n","Epoch 7/50\n","1558/1558 - 40s - loss: 6.7244 - accuracy: 0.0292\n","Epoch 8/50\n","1558/1558 - 40s - loss: 6.5928 - accuracy: 0.0299\n","Epoch 9/50\n","1558/1558 - 40s - loss: 6.4477 - accuracy: 0.0303\n","Epoch 10/50\n","1558/1558 - 40s - loss: 6.2696 - accuracy: 0.0327\n","Epoch 11/50\n","1558/1558 - 40s - loss: 6.0690 - accuracy: 0.0343\n","Epoch 12/50\n","1558/1558 - 40s - loss: 5.8477 - accuracy: 0.0372\n","Epoch 13/50\n","1558/1558 - 40s - loss: 5.6047 - accuracy: 0.0428\n","Epoch 14/50\n","1558/1558 - 40s - loss: 5.3621 - accuracy: 0.0641\n","Epoch 15/50\n","1558/1558 - 40s - loss: 5.1390 - accuracy: 0.1000\n","Epoch 16/50\n","1558/1558 - 40s - loss: 4.9465 - accuracy: 0.1346\n","Epoch 17/50\n","1558/1558 - 40s - loss: 4.7823 - accuracy: 0.1592\n","Epoch 18/50\n","1558/1558 - 40s - loss: 4.6365 - accuracy: 0.1796\n","Epoch 19/50\n","1558/1558 - 40s - loss: 4.5119 - accuracy: 0.1963\n","Epoch 20/50\n","1558/1558 - 40s - loss: 4.4010 - accuracy: 0.2117\n","Epoch 21/50\n","1558/1558 - 40s - loss: 4.3009 - accuracy: 0.2220\n","Epoch 22/50\n","1558/1558 - 40s - loss: 4.2133 - accuracy: 0.2330\n","Epoch 23/50\n","1558/1558 - 40s - loss: 4.1314 - accuracy: 0.2433\n","Epoch 24/50\n","1558/1558 - 40s - loss: 4.0577 - accuracy: 0.2528\n","Epoch 25/50\n","1558/1558 - 40s - loss: 3.9872 - accuracy: 0.2616\n","Epoch 26/50\n","1558/1558 - 40s - loss: 3.9238 - accuracy: 0.2686\n","Epoch 27/50\n","1558/1558 - 40s - loss: 3.8654 - accuracy: 0.2769\n","Epoch 28/50\n","1558/1558 - 40s - loss: 3.8109 - accuracy: 0.2843\n","Epoch 29/50\n","1558/1558 - 40s - loss: 3.7573 - accuracy: 0.2908\n","Epoch 30/50\n","1558/1558 - 40s - loss: 3.7113 - accuracy: 0.2946\n","Epoch 31/50\n","1558/1558 - 40s - loss: 3.6635 - accuracy: 0.3013\n","Epoch 32/50\n","1558/1558 - 40s - loss: 3.6200 - accuracy: 0.3078\n","Epoch 33/50\n","1558/1558 - 40s - loss: 3.5780 - accuracy: 0.3130\n","Epoch 34/50\n","1558/1558 - 40s - loss: 3.5368 - accuracy: 0.3178\n","Epoch 35/50\n","1558/1558 - 40s - loss: 3.4997 - accuracy: 0.3244\n","Epoch 36/50\n","1558/1558 - 40s - loss: 3.4619 - accuracy: 0.3278\n","Epoch 37/50\n","1558/1558 - 40s - loss: 3.4272 - accuracy: 0.3328\n","Epoch 38/50\n","1558/1558 - 40s - loss: 3.3924 - accuracy: 0.3366\n","Epoch 39/50\n","1558/1558 - 40s - loss: 3.3606 - accuracy: 0.3426\n","Epoch 40/50\n","1558/1558 - 40s - loss: 3.3282 - accuracy: 0.3457\n","Epoch 41/50\n","1558/1558 - 40s - loss: 3.2986 - accuracy: 0.3506\n","Epoch 42/50\n","1558/1558 - 40s - loss: 3.2684 - accuracy: 0.3539\n","Epoch 43/50\n","1558/1558 - 40s - loss: 3.2398 - accuracy: 0.3575\n","Epoch 44/50\n","1558/1558 - 40s - loss: 3.2147 - accuracy: 0.3624\n","Epoch 45/50\n","1558/1558 - 40s - loss: 3.1845 - accuracy: 0.3656\n","Epoch 46/50\n","1558/1558 - 40s - loss: 3.1619 - accuracy: 0.3710\n","Epoch 47/50\n","1558/1558 - 40s - loss: 3.1363 - accuracy: 0.3734\n","Epoch 48/50\n","1558/1558 - 40s - loss: 3.1113 - accuracy: 0.3755\n","Epoch 49/50\n","1558/1558 - 40s - loss: 3.0914 - accuracy: 0.3794\n","Epoch 50/50\n","1558/1558 - 40s - loss: 3.0670 - accuracy: 0.3821\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f25cd986588>"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"8PJW5fYsX7qQ","colab_type":"text"},"source":["# --------------------------------------------------------------------"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"VbzhDIpZX7qQ","colab_type":"code","colab":{}},"source":["# for _ in list(range(10,160,10)):\n","model_skip = Word2Vec(\n","result_gensim_input, \n","window = 2,\n","size =100,\n","min_count=1,\n","workers = 10\n",")\n","print(_)\n","print('집값삼각형 : ', model_skip.most_similar('집값삼각형',topn=5))\n","print()\n","print('도영 : ', model_skip.most_similar('도영',topn=5))\n","print()\n","print('싸인 : ', model_skip.most_similar('싸인',topn=5))\n","print()\n","print('수박 : ',model_skip.most_similar('수박',topn=5)) \n","print()\n","print('가게대변인 : ',model_skip.most_similar('가게대변인',topn=5))\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"itLQpnikX7qS","colab_type":"code","colab":{}},"source":["# model_skip = Word2Vec(\n","#     result_gensim_input, \n","#     window = 2,\n","#     size =40,\n","#     min_count=1,\n","#     sg = 1,\n","#     workers = 10\n","# )\n","# print(model_skip)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U0mZzSBCX7qV","colab_type":"code","colab":{}},"source":["model_skip.most_similar('집값삼각형',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BgW4XmfSX7qY","colab_type":"code","colab":{}},"source":["model_skip.most_similar('도영',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B3XMbR4BX7qb","colab_type":"code","colab":{}},"source":["model_skip.most_similar('싸인',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IYctj0ZlX7qe","colab_type":"code","colab":{}},"source":["model_skip.most_similar('수박',topn=10) #특수각"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ff1hCl_mX7qg","colab_type":"code","colab":{}},"source":["model_skip.most_similar('가게대변인',topn=10) #각의대변"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3XNrWRgVX7qi","colab_type":"code","colab":{}},"source":["model_skip.most_similar('추위',topn=10) #최애"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HMODL9kCX7qk","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AqlUitUoX7qn","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_9-j_L_X7qp","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9RMujjAvX7qr","colab_type":"code","colab":{}},"source":["model_skip.most_similar('',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kApqKO8CX7qt","colab_type":"code","colab":{}},"source":["model_skip.most_similar('',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Z-bovv9X7qw","colab_type":"code","colab":{}},"source":["model_skip.most_similar('',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OvBB1cY2X7qy","colab_type":"code","colab":{}},"source":["model_skip.most_similar('',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vBQUGaOHX7q0","colab_type":"code","colab":{}},"source":["model_skip.most_similar('',topn=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nO1Aw7uMX7q2","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yQyHWRHdX7q5","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8F4zlHFqX7q7","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UO5dx17mX7q9","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YM5b4J2AX7q_","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}