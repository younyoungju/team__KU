{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 문장끝에 . 붙여서 나누기\n",
    "1. how to put dot at the end of the each sentence?\n",
    "    - find the the end loc of the sentence using re and put comma\n",
    "        - how do we find the loc?\n",
    "            - using pattern#\n",
    "        - how do we add the commas?\n",
    "            - working on it \n",
    "            - might be using findall, or match\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install soynlp\n",
    "!pip install jamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lec00001_EBS.txt', 'lec00002_EBS.txt', 'lec00003_EBS.txt', 'lec00004_EBS.txt', 'lec00005_EBS.txt', 'lec00006_EBS.txt', 'lec00007_EBS.txt', 'lec00008_EBS.txt', 'lec00009_EBS.txt', 'lec00010_EBS.txt', 'lec00011_EBS.txt', 'lec00012_EBS.txt', 'lec00013_EBS.txt', 'lec00014_EBS.txt', 'lec00015_EBS.txt', 'lec00016_EBS.txt', 'lec00017_EBS.txt', 'lec00018_EBS.txt', 'lec00019_EBS.txt', 'lec00020_EBS.txt', 'lec00021_EBS.txt', 'lec00022_EBS.txt', 'lec00023_EBS.txt', 'lec00024_EBS.txt', 'lec00025_EBS.txt', 'lec00026_EBS.txt']\n"
     ]
    }
   ],
   "source": [
    "from PreProcessing.find_common_part import find_common_part\n",
    "import re\n",
    "from PreProcessing.Opentext import get_EBS\n",
    "from PreProcessing.Opentext import get_EBS_entered\n",
    "from PreProcessing.Opentext import get_STT1_Google_entered\n",
    "from PreProcessing.Opentext import get_STT1_Transcribe_entered\n",
    "from string import punctuation\n",
    "from jamo import h2j, j2hcj, j2h\n",
    "#from soynlp.hangle import levenshtein\n",
    "#from soynlp.hangle import jamo_levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "5\n",
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from PreProcessing.Dictionary import sd, ad, kopro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PreProcessing.Opentext import get_STT1_Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimalnumber_to_korean(m):\n",
    "    answer = ''\n",
    "    for _ in m.group(1):\n",
    "        answer += kopro[int(_)]\n",
    "    answer += '점'\n",
    "    for _ in m.group(3):\n",
    "        answer += kopro[int(_)]\n",
    "    return answer\n",
    "\n",
    "def number_to_korean(s):\n",
    "    #소수점 한국어로\n",
    "    s = re.sub(r'(\\d+)(\\.)(\\d+)', decimalnumber_to_korean, s)\n",
    "    \n",
    "    #정수 한국어로\n",
    "    fl = re.findall(r'\\d+', s)\n",
    "    fl = set(fl)\n",
    "    fl = [int(_) for _ in fl]\n",
    "    fl.sort(reverse=True)\n",
    "    fl = [str(_) for _ in fl]\n",
    "    for n in fl:\n",
    "        s = s.replace(n, kopro[int(n)])\n",
    "    return s\n",
    "\n",
    "def mathsymbol_to_korean(s):\n",
    "    for ms in sd.keys():\n",
    "        if ms in s:\n",
    "            s = s.replace(ms, sd[ms])\n",
    "    return s\n",
    "\n",
    "def alphabet_to_korean(s):\n",
    "    for a in ad.keys():\n",
    "        if a in s:\n",
    "            s = s.replace(a, ad[a])\n",
    "    return s\n",
    "\n",
    "def remove_newlines(s):\n",
    "    \n",
    "    return re.sub(r'[\\n]+', ' ', s)\n",
    "\n",
    "def remove_puncuations(s):\n",
    "    \n",
    "    return re.sub(r'[\\.?,‘’]+', ' ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_dot(text, dot):\n",
    "    pattern0 = re.compile('[다](?=\\S)')\n",
    "    pattern1 = re.compile('(ㅂㄴㅣㄷㅏ)$')   #ㅂ 니다\n",
    "#     #pattern2 = re.compile(r'(ㅇㅛ)$') # ㅔ요, ㅏ요, ㅓ요\n",
    "#     pattern3 = re.compile(r'(ㅆ)(ㅈ|ㅊ)(ㅛ)$') \n",
    "#     #pattern4 = re.compile(r'(ㅂ|ㅣ)(ㄴㅣㄲㅏ)$')  #ㅂ니까\\\n",
    "#     pattern4 = re.compile(r'(ㅣㅇㅑ)$')\n",
    "#     pattern5 = re.compile(r'(ㄴㄷㅔ)$')\n",
    "#     pattern2 = re.compile('[데](?=\\S)')\n",
    "    text_list = []\n",
    "    \n",
    "    _0 = 0\n",
    "    _1 = 0\n",
    "    _2 = 0\n",
    "    _3 = 0\n",
    "    _4 = 0\n",
    "    _5 = 0\n",
    "    _6 = 0\n",
    "    \n",
    "    for _ in text.split(' '):\n",
    "        new_ = j2hcj(h2j(_))\n",
    "        \n",
    "        if pattern0.findall(_):\n",
    "            text_list.append(pattern1.sub('다.',_))\n",
    "            _0 += 1\n",
    "            \n",
    "        elif pattern1.findall(new_):\n",
    "            text_list.append(_.replace(_, _+dot))\n",
    "            _1 += 1\n",
    "                      \n",
    "#         elif pattern2.findall(_):\n",
    "#             text_list.append(pattern2.sub('데.',_))\n",
    "#             _2 += 1\n",
    "                      \n",
    "#             #list2.append(_)\n",
    "#         elif pattern3.findall(new_):\n",
    "#             text_list.append(_.replace(_, _+dot))\n",
    "#             _3 += 1\n",
    "            \n",
    "                      \n",
    "#         elif pattern4.findall(new_):\n",
    "#             text_list.append(_.replace(_, _+dot))\n",
    "#             _4 += 1\n",
    "                      \n",
    "#         elif pattern5.findall(new_):\n",
    "#             text_list.append(_.replace(_,_+dot))\n",
    "#             _5 += 1\n",
    "                      \n",
    "        else:\n",
    "            text_list.append(_)\n",
    "            _6 += 1\n",
    "            #list6.append(_)\n",
    "    print('pattern0 = {},pattern1 = {}, pattern2= {}, pattern3 = {},patter4 = {}, pattern5 = {}, pattern6 = {}'.format(_0,_1,_2,_3,_4,_5,_6)) \n",
    "    #print('pattern2 = ',list2)#'\\n','list5 = ',list5)\n",
    "    print(len(text_list))\n",
    "    return text_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = []\n",
    "sample = '반갑습니다 습니다오늘 끝냅시다오늘 그런가보다들'\n",
    "sample_jamo = j2hcj(h2j('반갑습니다 습니다오늘 끝냈시다오늘'))\n",
    "pattern1 = re.compile('[다](?=\\S)')\n",
    "for _ in sample.split(' '):\n",
    "    if pattern1.findall(_):\n",
    "        alist.append(pattern1.sub('다.',_))\n",
    "alist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(get_EBS(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EBS 전처리\n",
    "def EBS_preprocessing(EBS):\n",
    "\n",
    "    \n",
    "#     수학기호 한국어로 변환(EBS)\n",
    "    ebs_math_conversion = mathsymbol_to_korean(EBS)\n",
    "        \n",
    "#     숫자 한국어로 변환(EBS)\n",
    "    ebs_number_conversion = number_to_korean(ebs_math_conversion)\n",
    "        \n",
    "#     알파벳 한국어로 변환(EBS)\n",
    "    ebs_alphabet_conversion = alphabet_to_korean(ebs_number_conversion)\n",
    "    \n",
    "#     특수문자 제거\n",
    "    ebs_punc_removed = remove_puncuations(ebs_alphabet_conversion)\n",
    "    \n",
    "#     점 집어넣기\n",
    "    ebs_dot_inserted = ' '.join(insert_dot(ebs_punc_removed,'.'))\n",
    "\n",
    "#     띄어쓰기 제거\n",
    "    #ebs_whitespace_removed = re.sub('[\\s]+', '', ebs_dot_inserted)\n",
    "\n",
    "    ebs_sep_by_lec = ebs_dot_inserted.replace('  ',' ')\n",
    "    return ebs_sep_by_lec.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOGLE 전처리\n",
    "def GOOGLE_preprocessing(GOOGLE):\n",
    "        \n",
    "#     개행 삭제\n",
    "    google_newline_removed = remove_newlines(GOOGLE)\n",
    "    \n",
    "#     수학기호 한국어로 변환\n",
    "    google_math_conversion = mathsymbol_to_korean(google_newline_removed)\n",
    "    \n",
    "#     숫자 한국어로 변환(GOOGLE)\n",
    "    google_number_conversion = number_to_korean(google_math_conversion)\n",
    "        \n",
    "#     알파벳 한국어로 변환(GOOGLE)\n",
    "    google_alphabet_conversion = alphabet_to_korean(google_number_conversion)\n",
    "    \n",
    "#     특수문자 제거\n",
    "    google_punc_removed = remove_puncuations(google_alphabet_conversion)\n",
    "    \n",
    "#     점 집어넣기\n",
    "    google_dot_inserted = ' '.join(insert_dot(google_punc_removed,'.'))\n",
    "    \n",
    "#     띄어쓰기 제거\n",
    "    #google_whitespace_removed = re.sub('[\\s]+', '', google_dot_inserted)\n",
    "\n",
    "    return google_dot_inserted.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EBS1 = EBS_preprocessing(get_EBS(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EBS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Google1 = get_STT1_Google(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Google1 = GOOGLE_preprocessing(Google1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Google1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_textE1 = ' '.join(insert_dot(EBS_ko[0],'.')).split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_textG1 = ' '.join(insert_dot(STT_pre[0],'.')).split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, d in zip(a, b):\n",
    "    print('EBS_sentence : ',c)\n",
    "    print('google_sentence : ', d)\n",
    "    print('EBS sentence length : {}, Google sentence length: {}'.format(len(c),len(d)))\n",
    "    print('common_part {}'.format(find_common_part(c, d)))\n",
    "    print('levenshtein = ', levenshtein(c,d))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_common_part('가나다라마', '가나다마')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 =  '차 이렇게 한번 그려보겠습니다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = '이렇게 이렇게 여기서부터 수선을 이렇게 커 보겠습니다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levenshtein(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_textG1), len(new_textE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_text(EBS_text, STT_text):\n",
    "    k_list = []\n",
    "    common_text = []\n",
    "    for (k,v) in enumerate(STT_text):\n",
    "\n",
    "        while k < 1:\n",
    "            for (q,w) in enumerate(EBS_text[k:k+6]):\n",
    "                x = levenshtein(v,w)\n",
    "                if x < 15:\n",
    "#                     print('k = ',k)\n",
    "#                     print('google:{}, Ebs:{}'.format(v,w))\n",
    "#                     print(x)\n",
    "#                     print(\"\")\n",
    "                    k_list.append(k)\n",
    "            break\n",
    "\n",
    "\n",
    "        while k == 1:\n",
    "            for (q,w) in enumerate(EBS_text[k-1:k+5]):\n",
    "                x = levenshtein(v,w)\n",
    "                if x <= 15:\n",
    "#                     print('k = ',k)\n",
    "#                     print('google:{}, Ebs:{}'.format(v,w))\n",
    "#                     print(x)\n",
    "#                     print(\"\")\n",
    "                    k_list.append(k)\n",
    "            break\n",
    "        \n",
    "        while k == 2:\n",
    "            for (q,w) in enumerate(EBS_text[k-2:k+4]):\n",
    "                x = levenshtein(v,w)\n",
    "                if x <= 15:\n",
    "#                     print('k = ',k)\n",
    "#                     print('google:{}, Ebs:{}'.format(v,w))\n",
    "#                     print(x)\n",
    "#                     print(\"\")\n",
    "                    k_list.append(k)\n",
    "            break\n",
    "\n",
    "\n",
    "        while k > 2:\n",
    "            for (q,w) in enumerate(EBS_text[k-2:k+4]):\n",
    "                x = levenshtein(v,w)\n",
    "                if x < 15:\n",
    "#                     print('k = ',k)\n",
    "#                     print('google:{}, Ebs:{}'.format(v,w))\n",
    "#                     print(x)\n",
    "#                     print(\"\")\n",
    "                    k_list.append(k)\n",
    "            break\n",
    "\n",
    "    print(len(set(k_list)))\n",
    "    print(set(k_list))\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_text(new_textE1, new_textG1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "63/len(new_textG1)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#제일 작은 levenshtein 값을 return 하는 것도 필요함\n",
    "#while q > k:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
